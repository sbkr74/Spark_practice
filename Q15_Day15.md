### Problem: You have a dataset of sales transactions, and you want to find the top-selling product for each month. Write a PySpark query to achieve this using window functions.

ðŸ“Š**Source Data:**  
Assume you have a PySpark DataFrame named `sales_data` with the following columns:
- `product_id` (String): The unique identifier for each product.
- `sales_date` (Date): The date of the sale.
- `sales_amount` (Double): The amount of the sale.

ðŸ”ŽHere's a sample of the source data:
```
+-----------+-----------+------------+
| product_id|sales_date |sales_amount|
+-----------+-----------+------------+
|     A     | 2023-01-15|   100.0    |
|     B     | 2023-01-20|   150.0    |
|     A     | 2023-02-10|   120.0    |
|     B     | 2023-02-15|   180.0    |
|     C     | 2023-03-05|   200.0    |
|     A     | 2023-03-10|   250.0    |
+-----------+-----------+------------+
```

ðŸ“Š**Expected Output:**  
You should generate a result Data Frame that shows the top-selling product for each month. The result should have the following columns:
- `month` (String): The month for which the top-selling product is calculated.
- `top_product` (String): The product that had the highest total sales for that month.

Here's the expected output for the provided sample data:
```
+-------+-----------+
| month |top_product|
+-------+-----------+
|2023-01|      B    |
|2023-02|      B    |
|2023-03|      A    |
+-------+-----------+
```